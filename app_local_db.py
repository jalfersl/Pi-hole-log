#!/usr/bin/env python3
"""
Pi-hole Log Viewer com Banco Local
Vers√£o otimizada que usa banco SQLite pr√≥prio para melhor performance
"""

from flask import Flask, render_template, request, jsonify, send_file
import sqlite3
import os
import json
import requests
import re
from datetime import datetime, timedelta
import subprocess
import paramiko
from config import FLASK_CONFIG, SSH_CONFIG

app = Flask(__name__)

# Configura√ß√µes
ALERT_SETTINGS_FILE = 'alert_settings.json'
DATA_RETENTION_DAYS = 90  # Padr√£o: 90 dias

def load_alert_settings():
    """Carregar configura√ß√µes de alerta"""
    if os.path.exists(ALERT_SETTINGS_FILE):
        with open(ALERT_SETTINGS_FILE, 'r') as f:
            settings = json.load(f)
            # Adicionar configura√ß√£o de reten√ß√£o se n√£o existir
            if 'data_retention_days' not in settings:
                settings['data_retention_days'] = DATA_RETENTION_DAYS
            return settings
    return {
        'alerts_enabled': True,
        'ip_spike_threshold': 3.0,
        'domain_spike_threshold': 5.0,
        'network_spike_threshold': 2.5,
        'analysis_period_hours': 2,
        'telegram_enabled': False,
        'telegram_chat_id': '',
        'telegram_bot_token': '',
        'data_retention_days': DATA_RETENTION_DAYS,
        'pdf_title': 'Relat√≥rio de Logs do Pi-hole',
        'pdf_author': 'Pi-hole Log Viewer',
        'pdf_subject': 'Relat√≥rio de Logs'
    }

def save_alert_settings(settings):
    """Salvar configura√ß√µes de alerta"""
    with open(ALERT_SETTINGS_FILE, 'w') as f:
        json.dump(settings, f, indent=2)

def send_telegram_notification(message):
    """Enviar notifica√ß√£o via Telegram"""
    settings = load_alert_settings()
    
    if not settings.get('telegramEnabled'):
        return False
    
    chat_id = settings.get('telegramChatId')
    bot_token = settings.get('telegramBotToken')
    
    if not chat_id or not bot_token:
        return False
    
    try:
        url = f"https://api.telegram.org/bot{bot_token}/sendMessage"
        data = {
            'chat_id': chat_id,
            'text': f"üö® **Pi-hole Alert**\n\n{message}",
            'parse_mode': 'Markdown'
        }
        
        response = requests.post(url, data=data, timeout=10)
        response_data = response.json()
        
        if response.status_code == 200 and response_data.get('ok'):
            return True
        else:
            error_msg = response_data.get('description', 'Erro desconhecido')
            print(f"Erro Telegram API: {error_msg}")
            return False
    except Exception as e:
        print(f"Erro ao enviar notifica√ß√£o Telegram: {e}")
        return False

def check_all_alerts():
    """Verificar todos os alertas"""
    settings = load_alert_settings()
    
    if not settings.get('alerts_enabled'):
        return []
    
    alerts = []
    
    # Verificar picos de tr√°fego por IP
    try:
        conn = sqlite3.connect('pihole_logs.db')
        cursor = conn.cursor()
        
        # An√°lise de picos por IP
        cursor.execute("""
            SELECT client, COUNT(*) as count
            FROM queries 
            WHERE timestamp >= datetime('now', '-2 hours')
            GROUP BY client
            ORDER BY count DESC
            LIMIT 10
        """)
        
        recent_ips = cursor.fetchall()
        
        if recent_ips:
            # Calcular m√©dia hist√≥rica
            cursor.execute("""
                SELECT client, AVG(count) as avg_count
                FROM (
                    SELECT client, COUNT(*) as count
                    FROM queries 
                    WHERE timestamp >= datetime('now', '-24 hours')
                    GROUP BY client, strftime('%H', timestamp)
                )
                GROUP BY client
            """)
            
            historical_avg = cursor.fetchall()
            avg_dict = {ip: avg for ip, avg in historical_avg}
            
            for ip, count in recent_ips:
                if ip in avg_dict and avg_dict[ip] > 0:
                    ratio = count / avg_dict[ip]
                    if ratio > settings.get('ip_spike_threshold', 3.0):
                        alerts.append({
                            'type': 'warning',
                            'severity': 'M√©dio',
                            'title': f'Pico de Tr√°fego - IP {ip}',
                            'message': f'IP {ip} apresentou {count} consultas nas √∫ltimas 2 horas (m√©dia: {avg_dict[ip]:.1f})',
                            'timestamp': datetime.now().isoformat()
                        })
        
        conn.close()
        
    except Exception as e:
        print(f"Erro ao verificar alertas: {e}")
    
    # Enviar notifica√ß√µes se houver alertas
    if alerts and settings.get('telegramEnabled'):
        for alert in alerts:
            send_telegram_notification(alert['message'])
    
    return alerts

@app.route('/')
def index():
    """P√°gina principal - Dashboard"""
    return render_template('dashboard.html')

@app.route('/logs')
def logs():
    """P√°gina de logs"""
    return render_template('logs.html')

@app.route('/config')
def config():
    """P√°gina de configura√ß√µes"""
    return render_template('config.html')

# API Routes
@app.route('/api/logs')
def api_logs():
    """API para buscar logs"""
    try:
        # Par√¢metros da requisi√ß√£o
        ip_search = request.args.get('ip', '').strip()
        domain_search = request.args.get('domain', '').strip()
        start_date = request.args.get('start_date')
        end_date = request.args.get('end_date')
        start_time = request.args.get('start_time', '00:00')
        end_time = request.args.get('end_time', '23:59')
        lines = request.args.get('lines', 5000, type=int)
        
        conn = sqlite3.connect('pihole_logs.db')
        cursor = conn.cursor()
        
        # Construir query base com agrupamento por dom√≠nio, IP e status apenas
        sql = """
            SELECT 
                domain,
                client,
                status,
                COUNT(*) as count,
                MAX(timestamp) as last_seen
            FROM queries 
            WHERE 1=1
        """
        params = []
        
        # Adicionar filtros
        if ip_search:
            sql += " AND client LIKE ?"
            params.append(f"%{ip_search}%")
        
        if domain_search:
            sql += " AND domain LIKE ?"
            params.append(f"%{domain_search}%")
        
        if start_date:
            start_datetime = f"{start_date} {start_time}"
            sql += " AND timestamp >= ?"
            params.append(start_datetime)
        
        if end_date:
            end_datetime = f"{end_date} {end_time}"
            sql += " AND timestamp <= ?"
            params.append(end_datetime)
        
        # Agrupar apenas por dom√≠nio, IP e status (sem considerar timestamp)
        sql += " GROUP BY domain, client, status"
        
        # Ordenar por contagem decrescente
        sql += " ORDER BY count DESC"
        
        # Limitar resultados
        sql += f" LIMIT {lines}"
        
        cursor.execute(sql, params)
        rows = cursor.fetchall()
        
        # Converter para formato esperado
        logs = []
        for row in rows:
            log = {
                'domain': row[0],
                'ip': row[1],
                'status': row[2],
                'count': row[3],
                'timestamp': row[4]  # √∫ltimo acesso
            }
            logs.append(log)
        
        conn.close()
        
        return jsonify({
            'success': True,
            'logs': logs,
            'total_found': len(logs),
            'total_returned': len(logs),
            'limited': len(logs) >= lines
        })
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/stats')
def api_stats():
    """API para estat√≠sticas do dashboard"""
    try:
        conn = sqlite3.connect('pihole_logs.db')
        cursor = conn.cursor()
        
        # Total de consultas
        cursor.execute("SELECT COUNT(*) FROM queries")
        total_queries = cursor.fetchone()[0]
        
        # Consultas bloqueadas
        cursor.execute("SELECT COUNT(*) FROM queries WHERE status = 'blocked'")
        blocked_queries = cursor.fetchone()[0]
        
        # Clientes √∫nicos
        cursor.execute("SELECT COUNT(DISTINCT client) FROM queries")
        unique_clients = cursor.fetchone()[0]
        
        # Taxa de bloqueio
        block_rate = (blocked_queries / total_queries * 100) if total_queries > 0 else 0
        
        conn.close()
        
        return jsonify({
            'success': True,
            'stats': {
                'total_queries': total_queries,
                'blocked_queries': blocked_queries,
                'unique_clients': unique_clients,
                'block_rate': round(block_rate, 1)
            }
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/activity-chart')
def api_activity_chart():
    """API para gr√°fico de atividade"""
    try:
        conn = sqlite3.connect('pihole_logs.db')
        cursor = conn.cursor()
        
        # Dados apenas do dia atual por hora
        cursor.execute("""
            SELECT 
                strftime('%H', timestamp) as hour,
                COUNT(*) as total,
                SUM(CASE WHEN status = 'blocked' THEN 1 ELSE 0 END) as blocked
            FROM queries 
            WHERE date(timestamp) = date('now')
            GROUP BY strftime('%H', timestamp)
            ORDER BY hour
        """)
        
        data = cursor.fetchall()
        
        labels = [f"{hour}:00" for hour, _, _ in data]
        queries = [total for _, total, _ in data]
        blocked = [blocked for _, _, blocked in data]
        
        conn.close()
        
        return jsonify({
            'success': True,
            'data': {
                'labels': labels,
                'queries': queries,
                'blocked': blocked
            }
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/top-domains')
def api_top_domains():
    """API para top dom√≠nios"""
    try:
        conn = sqlite3.connect('pihole_logs.db')
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT domain, COUNT(*) as count
            FROM queries 
            WHERE timestamp >= datetime('now', '-24 hours')
            GROUP BY domain
            ORDER BY count DESC
            LIMIT 10
        """)
        
        domains = [{'domain': domain, 'count': count} for domain, count in cursor.fetchall()]
        conn.close()
        
        return jsonify({'success': True, 'domains': domains})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/top-blocked-domains')
def api_top_blocked_domains():
    """API para top dom√≠nios bloqueados"""
    try:
        conn = sqlite3.connect('pihole_logs.db')
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT domain, COUNT(*) as count
            FROM queries 
            WHERE timestamp >= datetime('now', '-24 hours')
            AND status = 'blocked'
            GROUP BY domain
            ORDER BY count DESC
            LIMIT 10
        """)
        
        domains = [{'domain': domain, 'count': count} for domain, count in cursor.fetchall()]
        conn.close()
        
        return jsonify({'success': True, 'domains': domains})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/top-ips')
def api_top_ips():
    """API para top IPs"""
    try:
        conn = sqlite3.connect('pihole_logs.db')
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT client, COUNT(*) as count
            FROM queries 
            WHERE timestamp >= datetime('now', '-24 hours')
            AND client != '127.0.0.1'
            GROUP BY client
            ORDER BY count DESC
            LIMIT 10
        """)
        
        ips = [{'ip': ip, 'count': count} for ip, count in cursor.fetchall()]
        conn.close()
        
        return jsonify({'success': True, 'ips': ips})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/recent-activity')
def api_recent_activity():
    """API para atividade recente"""
    try:
        conn = sqlite3.connect('pihole_logs.db')
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT timestamp, domain, client, status
            FROM queries 
            ORDER BY timestamp DESC
            LIMIT 20
        """)
        
        activities = []
        for timestamp, domain, client, status in cursor.fetchall():
            activities.append({
                'timestamp': timestamp,
                'domain': domain,
                'ip': client,
                'status': 'blocked' if status == 'blocked' else 'allowed'
            })
        
        conn.close()
        
        return jsonify({'success': True, 'activities': activities})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/alerts')
def api_alerts():
    """API para alertas"""
    try:
        alerts = check_all_alerts()
        return jsonify({'success': True, 'alerts': alerts})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/check-alerts')
def api_check_alerts():
    """API para verificar alertas"""
    try:
        alerts = check_all_alerts()
        return jsonify({'success': True, 'alerts': alerts})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

# Configura√ß√µes
@app.route('/api/config', methods=['GET', 'POST'])
def api_config():
    """API para configura√ß√µes"""
    if request.method == 'POST':
        try:
            data = request.json
            save_alert_settings(data)
            return jsonify({'success': True})
        except Exception as e:
            return jsonify({'success': False, 'error': str(e)})
    else:
        try:
            settings = load_alert_settings()
            return jsonify({'success': True, 'settings': settings})
        except Exception as e:
            return jsonify({'success': False, 'error': str(e)})

@app.route('/api/test-notification')
def api_test_notification():
    """API para testar notifica√ß√£o"""
    try:
        settings = load_alert_settings()
        
        if not settings.get('telegramEnabled'):
            return jsonify({'success': False, 'error': 'Telegram n√£o habilitado'})
        
        message = "üß™ **Teste de Notifica√ß√£o**\n\nEsta √© uma notifica√ß√£o de teste do Pi-hole Log Viewer."
        
        if send_telegram_notification(message):
            return jsonify({'success': True, 'message': 'Notifica√ß√£o enviada com sucesso!'})
        else:
            return jsonify({'success': False, 'error': 'Bot foi bloqueado pelo usu√°rio. Desbloqueie o bot no Telegram e tente novamente.'})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/update-data')
def api_update_data():
    """API para atualizar dados do Pi-hole"""
    try:
        # Verificar se √© primeira atualiza√ß√£o (banco vazio)
        conn = sqlite3.connect('pihole_logs.db')
        cursor = conn.cursor()
        cursor.execute("SELECT COUNT(*) FROM queries")
        current_count = cursor.fetchone()[0]
        
        # Obter hor√°rio atual para limitar importa√ß√£o
        current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        # Se banco vazio, pegar dados at√© o hor√°rio atual
        if current_count == 0:
            print(f"üîÑ Primeira atualiza√ß√£o: Importando dados at√© {current_time}...")
            # Converter hor√°rio local para UTC para a query
            current_utc = (datetime.strptime(current_time, '%Y-%m-%d %H:%M:%S') + timedelta(hours=3)).strftime('%Y-%m-%d %H:%M:%S')
            command = f"sqlite3 /etc/pihole/pihole-FTL.db 'SELECT datetime(timestamp, \"unixepoch\"), domain, client, status FROM queries WHERE datetime(timestamp, \"unixepoch\") <= \"{current_utc}\" ORDER BY timestamp DESC;'"
        else:
            # Pegar apenas registros mais recentes que o √∫ltimo no banco local, mas at√© o hor√°rio atual
            cursor.execute("SELECT MAX(timestamp) FROM queries")
            last_timestamp = cursor.fetchone()[0]
            if last_timestamp:
                print(f"üîÑ Atualiza√ß√£o incremental: Importando registros ap√≥s {last_timestamp} at√© {current_time}...")
                # Converter hor√°rio local para UTC para a query
                current_utc = (datetime.strptime(current_time, '%Y-%m-%d %H:%M:%S') + timedelta(hours=3)).strftime('%Y-%m-%d %H:%M:%S')
                command = f"sqlite3 /etc/pihole/pihole-FTL.db 'SELECT datetime(timestamp, \"unixepoch\"), domain, client, status FROM queries WHERE timestamp > (SELECT strftime(\"%s\", \"{last_timestamp}\")) AND datetime(timestamp, \"unixepoch\") <= \"{current_utc}\" ORDER BY timestamp DESC;'"
            else:
                print(f"üîÑ Atualiza√ß√£o: Importando dados das √∫ltimas 24 horas at√© {current_time}...")
                # Converter hor√°rio local para UTC para a query
                current_utc = (datetime.strptime(current_time, '%Y-%m-%d %H:%M:%S') + timedelta(hours=3)).strftime('%Y-%m-%d %H:%M:%S')
                command = f"sqlite3 /etc/pihole/pihole-FTL.db 'SELECT datetime(timestamp, \"unixepoch\"), domain, client, status FROM queries WHERE timestamp >= strftime(\"%s\", \"now\", \"-24 hours\") AND datetime(timestamp, \"unixepoch\") <= \"{current_utc}\" ORDER BY timestamp DESC;'"
        
        conn.close()
        
        # Conectar ao servidor Pi-hole via SSH
        ssh = paramiko.SSHClient()
        ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
        
        ssh.connect(
            SSH_CONFIG['host'],
            port=SSH_CONFIG.get('port', 22),
            username=SSH_CONFIG['username'],
            password=SSH_CONFIG['password']
        )
        
        # Executar comando para obter dados do Pi-hole FTL
        stdin, stdout, stderr = ssh.exec_command(command)
        output = stdout.read().decode('utf-8')
        error = stderr.read().decode('utf-8')
        
        ssh.close()
        
        if error:
            return jsonify({'success': False, 'error': f'Erro SSH: {error}'})
        
        # Processar dados e inserir no banco local
        conn = sqlite3.connect('pihole_logs.db')
        cursor = conn.cursor()
        
        # Carregar configura√ß√µes
        settings = load_alert_settings()
        retention_days = settings.get('data_retention_days', DATA_RETENTION_DAYS)
        
        # Limpar dados antigos baseado na configura√ß√£o
        cursor.execute(f"DELETE FROM queries WHERE timestamp < datetime('now', '-{retention_days} days')")
        
        # Inserir novos dados
        lines = output.strip().split('\n')
        inserted_count = 0
        skipped_future = 0
        
        print(f"üîÑ Processando {len(lines)} linhas de dados...")
        
        for line in lines:
            if line.strip():
                try:
                    parts = line.split('|')
                    if len(parts) >= 4:
                        timestamp, domain, client, status = parts[:4]
                        
                        # Verificar se o timestamp n√£o √© futuro
                        # Converter timestamp para datetime para compara√ß√£o
                        try:
                            timestamp_dt = datetime.strptime(timestamp, '%Y-%m-%d %H:%M:%S')
                            current_dt = datetime.strptime(current_time, '%Y-%m-%d %H:%M:%S')
                            
                            # O Pi-hole usa UTC, ent√£o precisamos converter para hor√°rio local
                            # Subtrair 3 horas para converter UTC para hor√°rio local (-03)
                            timestamp_local = timestamp_dt - timedelta(hours=3)
                            
                            # Verificar se o timestamp convertido n√£o √© futuro
                            if timestamp_local <= current_dt + timedelta(hours=1):
                                # Mapear status do Pi-hole para nosso formato
                                # Status 1 = bloqueado, outros = permitido
                                mapped_status = 'blocked' if status == '1' else 'allowed'
                                
                                # Inserir no banco local com timestamp convertido para hor√°rio local
                                local_timestamp = timestamp_local.strftime('%Y-%m-%d %H:%M:%S')
                                
                                cursor.execute("""
                                    INSERT OR IGNORE INTO queries (timestamp, domain, client, status)
                                    VALUES (?, ?, ?, ?)
                                """, (local_timestamp, domain, client, mapped_status))
                                inserted_count += 1
                                
                                if inserted_count % 1000 == 0:
                                    print(f"‚úÖ Processados {inserted_count} registros...")
                            else:
                                skipped_future += 1
                                if skipped_future <= 5:  # Log apenas os primeiros 5
                                    print(f"‚ö†Ô∏è Ignorando registro futuro: {timestamp} (convertido: {local_timestamp}, atual: {current_time})")
                        except ValueError as e:
                            print(f"‚ö†Ô∏è Erro ao processar timestamp: {timestamp} - {e}")
                            continue
                except Exception as e:
                    print(f"Erro ao processar linha: {line} - {e}")
                    continue
        
        print(f"‚úÖ Importa√ß√£o conclu√≠da: {inserted_count} inseridos, {skipped_future} futuros ignorados")
        
        conn.commit()
        conn.close()
        
        return jsonify({
            'success': True, 
            'message': f'Dados atualizados com sucesso! {inserted_count} registros inseridos, {skipped_future} futuros ignorados.',
            'inserted_count': inserted_count,
            'skipped_future': skipped_future,
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'total_records': current_count + inserted_count,
            'retention_days': retention_days,
            'current_time': current_time
        })
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

if __name__ == '__main__':
    app.run(**FLASK_CONFIG) 